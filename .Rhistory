setwd("C:/Users/yche465/Desktop/AIM 1/Codes/PrEP-Traj-Clustering/")
#load relevant R project environment
renv::load(getwd())
#check if any packages from the R project need to be installed
renv::restore()
#install packages (if needed)
##install.packages('gt')
##install.packages('webshot2')
##install.packages("matrixStats")
#load libraries
library(here)
library(gt)
library(webshot2)
library(matrixStats)
library(here)
library(lcmm)
library(ggplot2)
library(ggpubr)
here()
#import plot theme set-up
source(here("misc/plot_theme.R"))
################################################################################################
# Import model fitness statistics
fit=readRDS(here("./Export/Stats_data4k_rep20maxit10"))
library(here)
fit=readRDS(here("./Export/Stats_data4k_rep20maxit10"))
fit
RUN1=readRDS(here("Export","paraRUN1"))
#load libraries
library(here)
RUN1=readRDS(here("Export","paraRUN1"))
T3=Sys.time()
# cl=makeCluster(detectCores()-1)
# clusterExport(cl,ls(),envir = environment())
# CONSPROB_ALL=parLapply(cl,1:length(RUN1),consensus_prob)
# stopCluster(cl)
CONSPROB_ALL=lapply(1:length(RUN1),consensus_prob)
source(here("Programs","Helper_Functions_GBTM.R"))
T3=Sys.time()
# cl=makeCluster(detectCores()-1)
# clusterExport(cl,ls(),envir = environment())
# CONSPROB_ALL=parLapply(cl,1:length(RUN1),consensus_prob)
# stopCluster(cl)
CONSPROB_ALL=lapply(1:length(RUN1),consensus_prob)
CONSPROB_ALL2=CONSPROB_ALL[[1]]
for (i in 2:length(CONSPROB_ALL)){
CONSPROB_ALL2=rbind(CONSPROB_ALL2,CONSPROB_ALL[[i]])
}
CONSPROB=CONSPROB_ALL2%>%dplyr::arrange(ID1,ID2)%>%
group_by(ID1,ID2)%>%
summarise(consensus_prob=mean(same.group.prob),N_per_pair=n())
T4=Sys.time()
TD2=difftime(T2,T1, units="mins")
TD2=difftime(T4,T3, units="mins")
TD2
Consensus.Probabilities=CONSPROB$consensus_prob
hist(Consensus.Probabilities)
CONSPROB
CONSPROB$consensus_prob
library(here)
library(utils)
library(lcmm)
library(tidyr)
library(renv)
library(dplyr)
library(rlang)
library(LCTMtools)
library(here)
library(ellipsis)
#load libraries
library(here)
library(gt)
library(webshot2)
library(matrixStats)
library(here)
library(lcmm)
library(ggplot2)
library(ggpubr)
# install.packages("tidyLPA")
library(tidyLPA)
# install.packages('mclust')
library(mclust)
source(here("misc/plot_theme.R"))
fit=readRDS(here("./Export/real/Stats_data4k_rep20maxit10"))
fit
#load libraries
library(lcmm)
library(tidyr)
library(renv)
library(dplyr)
library(rlang)
library(LCTMtools)
library(here)
library(ellipsis)
#Import input data --------------------------------------------------------------
SeroProtect=read.delim(here("./Data/SeroProtect_4k.txt"),sep=",",header=FALSE)
colnames(SeroProtect)=c("ID",sapply(1:103, function(i){
paste0("Protect",i)
}))
orig_ID=SeroProtect$ID #create original ID
SeroProtect['ID']=1:nrow(SeroProtect)  #create new analysis specific ID
new_ID=SeroProtect$ID
## Index object for linking original and analysis ID
sampled_ID_index=data.frame(ID_orig=orig_ID,
ID_new=new_ID)
SP_long=SeroProtect%>%tidyr::gather(., Week, Protect,Protect1:Protect103, factor_key=TRUE)
SP_long$Week=gsub("Protect","",SP_long$Week)%>%as.numeric()
SP_long=SP_long%>%arrange(ID,Week)
##scale down the time variable to facilitate model convergence
SP_long$Week=SP_long$Week/10
mod=list()
mod[[1]]=lcmm(Protect~1+Week+I(Week^2), subject='ID',ng=1,data=SP_long, link="thresholds", maxiter=200)
# Implement K=2~6 GBTM--------------------------------------------------------------------------
source(here("Programs","Helper_Functions_GBTM.R"))
num_rep=20
num_maxit=10
Ncore=detectCores()-1
Time_rep20maxit10=rep(NA,6)
mod[[2]]=mod[[3]]=mod[[4]]=mod[[5]]=mod[[6]]=NULL
SP_long
x=read.csv(here('Data','PersonVars_sampled.csv'))
x
## Index object for linking original and analysis ID
sampled_ID_index
SP_long
covar=read.csv(here('Data','PersonVars_sampled.csv'))
merge(x=SP_long_4k,y=sampled_ID_index,by="ID",all.x=TRUE)
merge(x=SP_long,y=sampled_ID_index,by="ID",all.x=TRUE)
head(sampled_ID_index)
## Index object for linking original and analysis ID
sampled_ID_index=data.frame(ID_orig=orig_ID,
ID=new_ID)
merge(x=SP_long,y=sampled_ID_index,by="ID",all.x=TRUE)
head(SeroProtect)
SeroProtect=read.delim(here("./Data/SeroProtect_4k.txt"),sep=",",header=FALSE)
head(SeroProtect)
covar=read.csv(here('Data','PersonVars_sampled.csv'))
SP_long2=merge(x=SP_long,y=sampled_ID_index,by="ID",all.x=TRUE)
SP_long2
SP_long3=merge(SP_long2,y=covar,by="ID_orig",all.x=TRUE)
covar$ID
-------------------
covar=read.csv(here('Data','PersonVars_sampled.csv'))%>%rename(ID_orig=ID)
# Append covariates to the long dataset -----------------------------------------------------
covar=read.csv(here('Data','PersonVars_sampled.csv'))%>%rename(ID_orig=ID)
# Append covariates to the long dataset -----------------------------------------------------
covar=read.csv(here('Data','PersonVars_sampled.csv'))%>%rename(ID_orig=ID)
SP_long2=merge(x=SP_long,y=sampled_ID_index,by="ID",all.x=TRUE)
SP_long3=merge(SP_long2,y=covar,by="ID_orig",all.x=TRUE)
head(SP_long3)
covar=read.csv(here('Data','PersonVars_sampled.csv'))%>%rename(ID_orig=ID)
SP_long2=merge(x=SP_long,y=sampled_ID_index,by="ID",all.x=TRUE)
SP_long3=merge(SP_long2,y=covar,by="ID_orig",all.x=TRUE)%>%dplyr::select(ID,Week,Protect,Age_at_init_cat,Average_copay_cat,Primary_payer,Pharmacy_type)
head(SP_long3)
mod
source(here("Programs","Helper_Functions_GBTM.R"))
num_rep=20
num_maxit=10
Ncore=detectCores()-1
Time_rep20maxit10=rep(NA,6)
mod[[2]]=mod[[3]]=mod[[4]]=mod[[5]]=mod[[6]]=NULL
for (k in 2:3){
cat("K=",k)
t1=Sys.time()
cl=makeCluster(Ncore-1)
clusterExport(cl,list("k",'lcmm'),environment())
mod[[k]]=gridsearch(rep = num_rep, maxiter = num_maxit, minit = mod[[1]],
lcmm(fixed=Protect~1+Week+I(Week^2),random=~-1, mixture=~1+Week+I(Week^2),
subject='ID',classmb =~Age_at_init_cat+Average_copay_cat+Primary_payer+Pharmacy_type,
ng=k,data=SP_long3, link="thresholds",nwg=FALSE),cl=cl)
stopCluster(cl)
t2=Sys.time()
Time_rep20maxit10[k]=difftime(t2,t1,units ='mins')
}
3129/60
Time_rep20maxit10[[2]]
Time_rep20maxit10[[1]]
Time_rep20maxit10[[3]]
saveRDS(mod,here("./Export/GBTM_fake_assoc"))
mod[[2]]$best
mod[[2]]$V
mod_assoc=mod
mod_assoc[[3]]$UACV
mod_assoc[[3]]$best
Modfit_assoc=GBTM_stat(mod_assoc)
Modfit_assoc
num_rep=20
num_maxit=10
Ncore=detectCores()-1
Time_rep20maxit10=rep(NA,6)
mod[[2]]=mod[[3]]=mod[[4]]=mod[[5]]=mod[[6]]=NULL
for (k in 2:3){
cat("K=",k)
t1=Sys.time()
cl=makeCluster(Ncore-1)
clusterExport(cl,list("k",'lcmm'),environment())
mod[[k]]=gridsearch(rep = num_rep, maxiter = num_maxit, minit = mod[[1]],
lcmm(fixed=Protect~1+Week+I(Week^2),random=~-1, mixture=~1+Week+I(Week^2),
subject='ID',
# classmb =~Age_at_init_cat+Average_copay_cat+Primary_payer+Pharmacy_type,
ng=k,data=SP_long3, link="thresholds",nwg=FALSE),cl=cl)
stopCluster(cl)
t2=Sys.time()
Time_rep20maxit10[k]=difftime(t2,t1,units ='mins')
}
mod[[3]]$best
mod[[2]]$best
mod_assoc[[2]]$best
mod_assoc[[3]]$best
mod[[3]]$best
summary(mod[[3]])
summary(mod[[3]])
summary(mod_assoc[[3]])
summary(mod[[3]])
summary(mod_assoc[[2]])
summary(mod_assoc[[3]])
mod_assoc[[3]]$V
summary(mod_assoc[[3]])$coef
coef(summary(mod_assoc[[3]]))
str(summary(mod_assoc[[3]]))
summary(mod_assoc[[3]])$coef
summary(mod_assoc[[3]])$'coef'
summary(mod_assoc[[3]])
parameters(mod[[2]])
mod[[2]]$conv
mod_assoc[[3]]$conv
mod_assoc[[2]]$conv
realmod=readRDS(here("Export","real","GBTM_data4k_rep20maxit10"))
realmod[[5]]
summary(realmod[[4]])
summary(realmod[[6]])
rm(list=ls())
#load libraries
library(lcmm)
library(tidyr)
library(renv)
library(dplyr)
library(rlang)
library(LCTMtools)
library(here)
library(ellipsis)
#Import input data --------------------------------------------------------------
SeroProtect=read.delim(here("./Data/SeroProtect_4k.txt"),sep=",",header=FALSE)
colnames(SeroProtect)=c("ID",sapply(1:103, function(i){
paste0("Protect",i)
}))
orig_ID=SeroProtect$ID #create original ID
SeroProtect['ID']=1:nrow(SeroProtect)  #create new analysis specific ID
new_ID=SeroProtect$ID
## Index object for linking original and analysis ID
sampled_ID_index=data.frame(ID_orig=orig_ID,
ID=new_ID)
# write.csv(sampled_ID_index, here("Export","Sampled_ID_index.csv"), row.names=FALSE)
#Convert wide to long format (with analysis ID) --------------------------------------------
SP_long=SeroProtect%>%tidyr::gather(., Week, Protect,Protect1:Protect103, factor_key=TRUE)
SP_long$Week=gsub("Protect","",SP_long$Week)%>%as.numeric()
SP_long=SP_long%>%arrange(ID,Week)
##scale down the time variable to facilitate model convergence
SP_long$Week=SP_long$Week/10
# saveRDS(SP_long,here("./Data/SP_long_4k"))
# Append covariates to the long dataset -----------------------------------------------------
covar=read.csv(here('Data','PersonVars_sampled.csv'))%>%rename(ID_orig=ID)
SP_long2=merge(x=SP_long,y=sampled_ID_index,by="ID",all.x=TRUE)
SP_long3=merge(SP_long2,y=covar,by="ID_orig",all.x=TRUE)%>%dplyr::select(ID,Week,Protect,Age_at_init_cat,Average_copay_cat,Primary_payer,Pharmacy_type)
#Run 1-group latent class trajectory model ---------------------------------------------------
init_mod=lcmm(Protect~1+Week+I(Week^2), subject='ID',ng=1,data=SP_long3, link="thresholds", maxiter=200)
